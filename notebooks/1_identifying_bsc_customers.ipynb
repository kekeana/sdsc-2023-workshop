{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying BSC Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: DFI Queries Will Not Work**\n",
    "\n",
    "**The Data Flow Index server used for this workshop is no longer running.  The workshop materials are left up _as is_ but queries will not run.  If you would like to trial the Data Flow Index please reach out to General System at [https://www.generalsystem.com/contact-us](https://www.generalsystem.com/contact-us).**\n",
    "\n",
    "This notebook is set to run for a single BSC location, but can be amended to run for all Blank Street Coffee customers. This can be done by removing the \"break\" lines in the dfi query code chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "from typing import Set\n",
    "\n",
    "import altair as alt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "from dfi import Client\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_location_data(filename: str, url: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\" \"Downloads the file at url and saves to a file called filename, returns gdf\n",
    "    e.g. url = \"https://d3ftlhu7xfb8rb.cloudfront.net/blank_street_coffees_callsigns.geoparquet\"\n",
    "    \"\"\"\n",
    "    Path(filename).parent.mkdir(parents=True, exist_ok=True)\n",
    "    http = urllib3.PoolManager()\n",
    "    with open(filename, \"wb\") as out:\n",
    "        r = http.request(\"GET\", url, preload_content=False)\n",
    "        shutil.copyfileobj(r, out)\n",
    "\n",
    "    return gpd.read_parquet(filename)\n",
    "\n",
    "\n",
    "def unpack_payload(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df[df[\"payload\"].apply(lambda x: isinstance(x, str))]  # filter out any problem payloads\n",
    "    df[\"route\"] = df[\"payload\"].apply(lambda x: json.loads(x)[\"route\"])\n",
    "    df[\"transportation_mode\"] = df[\"payload\"].apply(lambda x: json.loads(x)[\"transportation_mode\"])\n",
    "    df[\"start_location_id\"] = df[\"payload\"].apply(lambda x: json.loads(x)[\"start_location_id\"])\n",
    "    df[\"end_location_id\"] = df[\"payload\"].apply(lambda x: json.loads(x)[\"end_location_id\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load OSM & BSC Location Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in OSM building data\n",
    "osm_gdf = load_location_data(\"osm_gdf\", \"https://d3ftlhu7xfb8rb.cloudfront.net/london_nyc_osm.geoparquet\")\n",
    "osm_ids = osm_gdf[\"osm_id\"]\n",
    "\n",
    "# Load in Blank Street Coffee Location dataset\n",
    "bsc_gdf = load_location_data(\n",
    "    \"bsc_gdf\", \"https://d3ftlhu7xfb8rb.cloudfront.net/blank_street_coffee_callsigns.geoparquet\"\n",
    ")\n",
    "bsc_osm_ids = bsc_gdf[\"osm_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Identifying BSC Customers\n",
    "\n",
    "We say an entity is a customer of BSC if it has dwelled at one or more BSC cafes.  To identify the customers in the dataset we query the BSC building polygons for records within each and identify the unique IDs.  Since we want to identify just the entities that dwelled at the locations and not ones that just pass by, we need to pull all the records for each entity and calculate their dwells.  Here, since the data was synthetically generated, each record is labelled if it is `dwelling`, `walking`, `cycling`, or `driving`.  Once we've queried for the entitie's records, we simply filter for those with the `dwelling` label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise DFI\n",
    "token = getpass(\"Enter your API access token: \")\n",
    "instance = \"sdsc-2-2088\"  # sdsc-1-5148\n",
    "namespace = \"gs\"\n",
    "url = \"https://api.prod.generalsystem.com\"\n",
    "\n",
    "dfi = Client(token, instance, namespace, url, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a list of devices which have pings inside bsc locations\n",
    "bsc_entities: Set[str] = set([])\n",
    "for _, row in tqdm(bsc_gdf.iterrows(), total=len(bsc_gdf)):\n",
    "    entities = dfi.get.entities(\n",
    "        polygon=list(row.geometry.exterior.coords),\n",
    "    )\n",
    "    bsc_entities = bsc_entities.union(entities)\n",
    "    break  # Remove or comment out to run for all entities\n",
    "\n",
    "bsc_entities = list(bsc_entities)\n",
    "\n",
    "print(f\"There are {len(bsc_entities)} unique devices with data inside Blank Street Coffee: {row.callsign}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the records associated with those devices\n",
    "records_df = dfi.get.records([bsc_entities[1]], add_payload_as_json=True)\n",
    "records_df = unpack_payload(records_df)\n",
    "\n",
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_df = records_df[\n",
    "    records_df[\"start_location_id\"].isin(bsc_osm_ids) & records_df[\"transportation_mode\"] == \"dwelling\"\n",
    "]\n",
    "customers = records_df[\"entity_id\"].unique()\n",
    "\n",
    "customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Profiling Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we can begin the analysis. This section provides a brief overview of the customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = (\n",
    "    records_df[records_df[\"transportation_mode\"] == \"dwelling\"]\n",
    "    .rename(columns={\"entity_id\": \"customer_id\"})\n",
    "    .groupby(by=[\"customer_id\", \"route\"], as_index=False)\n",
    "    .agg(\n",
    "        start_time=(\"timestamp\", \"min\"),\n",
    "        end_time=(\"timestamp\", \"max\"),\n",
    "        location_id=(\"start_location_id\", \"first\"),\n",
    "    )\n",
    ")\n",
    "agg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many customers visited BSC locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df[\"entity_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many customers visited the same BSC shop more than once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsc_dwells_df = agg_df[agg_df[\"location_id\"].isin(bsc_osm_ids)]\n",
    "repeat_customers = bsc_dwells_df[bsc_dwells_df[\"entity_id\"].duplicated(keep=False)]\n",
    "repeat_customers[\"entity_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many customers visited multiple different BSC locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_location_counts = bsc_dwells_df.groupby(\"entity_id\")[\"location_id\"].nunique()\n",
    "(customer_location_counts > 1).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
